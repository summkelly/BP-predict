{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from  tensorflow.examples.tutorials.mnist  import  input_data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , 35.  , 23.  , ...,  4.  , 73.21,  2.  ],\n",
       "       [ 2.  , 42.  , 65.  , ...,  3.  , 69.64,  3.  ],\n",
       "       [ 3.  , 32.  , 81.  , ...,  4.  , 74.43,  2.  ],\n",
       "       ...,\n",
       "       [83.  , 37.  , 37.  , ...,  4.  , 69.04,  2.  ],\n",
       "       [84.  , 40.  , 21.  , ...,  5.  , 68.97,  0.  ],\n",
       "       [85.  , 41.  , 22.  , ...,  4.  , 78.59,  5.  ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/wang859923/Desktop/明星数据.csv', delimiter=\",\")\n",
    "x=np.array(dataset)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=5)\n",
    "# pca.fit(x)   \n",
    "# x=pca.fit_transform(x) \n",
    "# print(pca.explained_variance_ratio_)  #输出贡献率\n",
    "# print(x)                  #输出降维后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/wang859923/Desktop/婚姻状态.csv', delimiter=\",\")\n",
    "y=np.array(dataset)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "train= np.column_stack((x_train,y_train))\n",
    "test = np.column_stack((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, training accuracy = 1 \n",
      "step : 1, training accuracy = 1 \n",
      "step : 2, training accuracy = 1 \n",
      "step : 3, training accuracy = 1 \n",
      "step : 4, training accuracy = 1 \n",
      "step : 5, training accuracy = 1 \n",
      "step : 6, training accuracy = 1 \n",
      "step : 7, training accuracy = 1 \n",
      "step : 8, training accuracy = 1 \n",
      "step : 9, training accuracy = 1 \n"
     ]
    }
   ],
   "source": [
    "num_classes = 1  # 输出大小\n",
    "input_size = 17  # 输入大小\n",
    "hidden_units_size = 5  # 隐藏层节点数量\n",
    "batch_size = 10\n",
    "training_iterations = 10\n",
    "\n",
    "#设置占位符\n",
    "X = tf.placeholder(tf.float32, shape = [None, input_size])\n",
    "Y = tf.placeholder(tf.float32, shape = [None,num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#搭建三层神经网络: 2层hidden layer\n",
    "W1 = tf.Variable(tf.random_normal ([input_size, hidden_units_size], stddev = 0.1))\n",
    "B1 = tf.Variable(tf.constant (0.1), [hidden_units_size])\n",
    "W2 = tf.Variable(tf.random_normal ([hidden_units_size, hidden_units_size], stddev = 0.1))\n",
    "B2 = tf.Variable(tf.constant (0.1), [hidden_units_size])\n",
    "W3 = tf.Variable(tf.random_normal ([hidden_units_size, num_classes], stddev = 0.1))\n",
    "B3 = tf.Variable(tf.constant (0.1), [num_classes])\n",
    "\n",
    "hidden_opt1 = tf.matmul(X, W1) + B1  # 输入层到隐藏层1正向传播\n",
    "hidden_opt1 = tf.nn.dropout(hidden_opt1,keep_prob)  #dropout掉部分的结果\n",
    "hidden_opt1 = tf.nn.relu(hidden_opt1)  # 激活函数，用于计算节点输出值\n",
    "\n",
    "hidden_opt2 = tf.matmul(hidden_opt1, W2) + B2  # 隐藏层1到隐藏层2正向传播\n",
    "hidden_opt2 = tf.nn.dropout(hidden_opt2,keep_prob)  #dropout掉部分的结果\n",
    "hidden_opt2 = tf.nn.relu(hidden_opt2)  # 激活函数，用于计算节点输出值\n",
    "\n",
    "final_opt = tf.matmul(hidden_opt2, W3) + B3  # 隐藏层到输出层正向传播\n",
    "final_opt = tf.nn.dropout(final_opt,keep_prob)  #dropout掉部分的结果\n",
    "final_opt =tf.nn.sigmoid(final_opt) #通过sigmoud函数映射成为(0,1)之间值，表示概率\n",
    "\n",
    "\n",
    "# 对输出层计算交叉熵损失\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=final_opt))\n",
    "# 梯度下降算法，这里使用了反向传播算法用于修改权重，减小损失\n",
    "opt = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "# 计算准确率\n",
    "correct_prediction =tf.equal (tf.argmax (Y, 1), tf.argmax(final_opt, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "sess = tf.Session ()\n",
    "sess.run (init)\n",
    "    \n",
    "for i in range (training_iterations) :\n",
    "    # 训练\n",
    "    training_loss = sess.run ([opt, loss], feed_dict = {X: x_train, Y: y_train,keep_prob: 0.5})\n",
    "    train_accuracy = accuracy.eval (session = sess, feed_dict = {X: x_train,Y: y_train,keep_prob: 1})\n",
    "    print (\"step : %d, training accuracy = %g \" % (i, train_accuracy))\n",
    "    tf.argmax(final_opt, 1)\n",
    "    writer=tf.summary.FileWriter(r\"./path/to/log\",tf.get_default_graph())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.    , 42.    , 71.    ,  9.    ,  4.    , 77.19  ,  1.    ,\n",
       "         0.    ,  1.    ,  0.69  ,  5.    , 35.    , 11.    ,  9.    ,\n",
       "         4.    , 75.36  ,  4.    ],\n",
       "       [ 1.    , 37.    , 21.    ,  5.    ,  6.    , 77.95  ,  2.    ,\n",
       "         0.    ,  0.    ,  0.93  ,  0.6   , 25.    , 99.    ,  7.    ,\n",
       "         4.    , 27.49  ,  0.    ],\n",
       "       [ 1.    , 49.    , 71.    , 10.    ,  5.    , 69.97  ,  1.    ,\n",
       "         0.    ,  0.    ,  0.9795,  6.    , 32.    , 11.    ,  2.    ,\n",
       "         4.    , 83.48  ,  4.    ],\n",
       "       [ 1.    , 37.    , 51.    , 11.    ,  4.    , 83.29  ,  2.    ,\n",
       "         0.    ,  2.    ,  0.94  ,  8.    , 38.    , 51.    ,  4.    ,\n",
       "         4.    , 81.47  ,  2.    ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_predict = pd.read_csv('/Users/wang859923/Desktop/预测.csv', delimiter=\",\")\n",
    "x_predict = np.array(x_predict)\n",
    "x_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_value = sess.run(final_opt, feed_dict = {X: x_test, keep_prob: 1})\n",
    "# prediction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17438364],\n",
       "       [0.10909605],\n",
       "       [0.1546409 ],\n",
       "       [0.08820232]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_value = sess.run(final_opt, feed_dict = {X: x_predict, keep_prob: 1})\n",
    "prediction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
